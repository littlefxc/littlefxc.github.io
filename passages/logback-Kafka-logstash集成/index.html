<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.8.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="yanm1ng&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      logback+Kafka+logstash集成 | littlefxc&#39;s blog
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/css/plugins/gitment.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
    <script src="/js/gitment.js"></script>
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


</head>
<div class="wechat-share">
  <img src="/css/images/logo.png">
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>littlefxc's blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>logback+Kafka+logstash集成</h2>
  <p class="post-date">2019-06-26</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p>我们是通过 logback 打印日志，然后将日志通过 kafka 消息队列发送到 Logstash,经过处理以后存储到 Elasticsearch 中，然后通过 Kibana 图形化界面进行分析和处理。</p>
<p>在 spring boot 应用程序中，默认使用 logback 来记录日志，并用 INFO 级别输出日志到控制台。</p>
<p>日志级别和顺序：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL</p>
<p>Spring Boot官方推荐优先使用带有-spring的文件名作为,按照如下规则组织配置文件名，就能被正确加载:</p>
<p>logback-spring.xml &gt; logback-spring.groovy &gt; logback.xml &gt; logback.groovy</p>
<h2 id="1-logback-与-Kafka-的集成"><a href="#1-logback-与-Kafka-的集成" class="headerlink" title="1. logback 与 Kafka 的集成"></a>1. logback 与 Kafka 的集成</h2><p>logback 记录日志到 Kafka 消息队列中去，主要使用的是 <code>com.github.danielwegener:logback-kafka-appender:0.2.0-RC2</code> 这个依赖.</p>
<h3 id="1-1-KafkaAppender-配置说明"><a href="#1-1-KafkaAppender-配置说明" class="headerlink" title="1.1. KafkaAppender 配置说明"></a>1.1. KafkaAppender 配置说明</h3><p>由于Logback Encoder API中的重大更改，您需要至少使用logback版本1.2。</p>
<p>确保项目依赖中有：</p>
<p>[maven pom.xml]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.github.danielwegener&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;logback-kafka-appender&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.2.0-RC2&lt;/version&gt;</span><br><span class="line">    &lt;scope&gt;runtime&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.3&lt;/version&gt;</span><br><span class="line">    &lt;scope&gt;runtime&lt;/scope&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<p>[maven pom.xml]</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- This is the kafkaAppender --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"kafkaAppender"</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.KafkaAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">topic</span>&gt;</span>logs<span class="tag">&lt;/<span class="name">topic</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">keyingStrategy</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">deliveryStrategy</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"</span> /&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- 可选参数, 用于固定分区 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;partition&gt;0&lt;/partition&gt; --&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- 可选参数，用于在kafka消息中包含日志时间戳 --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;appendTimestamp&gt;true&lt;/appendTimestamp&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 每个&lt;producerConfig&gt;转换为常规kafka-client配置（格式：key = value） --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 生产者配置记录在这里：https//kafka.apache.org/documentation.html#newproducerconfigs --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- bootstrap.servers是唯一必需的 producerConfig --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>bootstrap.servers=localhost:9092<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 如果kafka不可用，这是后备appender。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"STDOUT"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 标准输出 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"STDOUT"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"kafkaAppender"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="1-2-兼容性-Compatibility"><a href="#1-2-兼容性-Compatibility" class="headerlink" title="1.2. 兼容性:Compatibility"></a>1.2. 兼容性:Compatibility</h3><p>logback-kafka-appender 依赖于 <code>org.apache.kafka:kafka-clients:1.0.0:jar</code>。它可以将日志附加到版本为 <code>0.9.0.0</code> 或更高版本的 kafka 代理。</p>
<p>对 <code>kafka-clients</code> 的依赖性不会被遮蔽，并且可以通过依赖性覆盖升级到更高的 api 兼容版本。</p>
<h3 id="1-3-分发策略-Delivery-strategies"><a href="#1-3-分发策略-Delivery-strategies" class="headerlink" title="1.3. 分发策略:Delivery strategies"></a>1.3. 分发策略:Delivery strategies</h3><p>直接通过网络进行日志记录并不是一件容易的事情，因为它可能不如本地文件系统可靠，并且如果传输出现问题，对应用程序性能的影响要大得多。</p>
<p>您需要做出一个重要的决定：是将所有日志传递到远程 Kafka 更重要，还是让应用程序保持平稳运行更为重要？这两个决定都允许您调整此 appender 以获得吞吐量。</p>
<ul>
<li><p>AsynchronousDeliveryStrategy: </p>
<p>  将每个日志消息分派给Kafka生成器。如果由于某些原因传递失败，则将消息发送给 fallback appenders。<br>  但是，如果生产者发送的缓冲区已满，这个交付策略就会阻塞(如果到代理的连接丢失，就会发生这种情况)。<br>  为了避免这种阻塞，可以启用 <code>producerConfig</code> <code>block.buffer.full=false</code>。<br>  所有不能足够快地交付的日志消息都将立即转到 fallback appenders。</p>
</li>
<li><p>BlockingDeliveryStrategy: </p>
<p>  将每条日志消息分派给Kafka Producer。如果由于某些原因导致传递失败，则会将消息分派给备用追加程序(fallback appender)。<br>  但是，如果生成器发送缓冲区已满，则此DeliveryStrategy 阻止每个调用线程，直到实际传递日志消息。<br>  通常不鼓励这种策略，因为它对吞吐量有很大的负面影响。警告：此策略不应与 <code>producerConfig</code> 一起使用 <code>linger.ms</code></p>
</li>
</ul>
<h4 id="1-3-1-关于-broker-的中断"><a href="#1-3-1-关于-broker-的中断" class="headerlink" title="1.3.1. 关于 broker 的中断"></a>1.3.1. 关于 broker 的中断</h4><p>AsynchronousDeliveryStrategy 不会阻止被Kafka元数据交换阻塞的应用程序。<br>这意味着：如果在日志记录上下文启动时无法访问所有代理，或者所有代理在较长时间内无法访问（&gt; metadata.max.age.ms），<br>则 appender 最终将阻塞。这种行为通常是不受欢迎的，可以使用 kafka-clients 0.9 进行迁移（参见＃16）。<br>在此之前，您可以使用 logback 自己的 AsyncAppender 包装 KafkaAppender。</p>
<p>示例配置可能如下所示：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- This is the kafkaAppender --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"kafkaAppender"</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.KafkaAppender"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Kafka Appender configuration --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"ASYNC"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.AsyncAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"kafkaAppender"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ASYNC"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="1-3-2-自定义分发策略-delivery-strategies"><a href="#1-3-2-自定义分发策略-delivery-strategies" class="headerlink" title="1.3.2. 自定义分发策略(delivery strategies)"></a>1.3.2. 自定义分发策略(delivery strategies)</h4><p>你可能使用自己的分发策略，只需继承 <code>com.github.danielwegener.logback.kafka.delivery.DeliveryStrategy</code></p>
<h4 id="1-3-3-备用追加程序-fallback-appender"><a href="#1-3-3-备用追加程序-fallback-appender" class="headerlink" title="1.3.3. 备用追加程序:fallback appender"></a>1.3.3. 备用追加程序:fallback appender</h4><p>如果由于某种原因，kafka-producer决定它无法发布日志消息，那么该消息仍然可以记录到 fallback appender（STDOUT 或 STDERR 上的 ConsoleAppender 将是一个合理的选择）。</p>
<p>只需将您的后备appender作为logback appender-ref添加到logback.xml中的KafkaAppender部分。 每个无法传递给kafka的消息都将写入所有已定义的appender-ref。</p>
<p>1.1 章节示例：<code>&lt;appender-ref ref =&quot;STDOUT&quot;&gt;</code> 中 <code>STDOUT</code> 是已定义的 appender。</p>
<p>请注意，AsynchronousDeliveryStrategy 将重用 kafka 生成器io线程将消息写入备用 appender。 因此，所有后备追加者应该是合理的快速，所以他们不会减慢或打破卡夫卡生产者。</p>
<h4 id="1-3-4-生产者调整"><a href="#1-3-4-生产者调整" class="headerlink" title="1.3.4. 生产者调整"></a>1.3.4. 生产者调整</h4><p>这个appender使用kafka-0.8.2中引入的 <a href="https://kafka.apache.org/documentation.html#producerconfigs" target="_blank" rel="noopener">kafka生成器</a>。 它使用生成器默认配置。</p>
<p>您可以使用 <code>&lt;producerConfig&gt; Name = Value &lt;/ producerConfig&gt;</code> 块覆盖任何已知的kafka生成器配置（请注意，boostrap.servers配置是必需的）。<br>这允许很多微调潜力（例如，使用batch.size，compression.type 和 linger.ms）。</p>
<h4 id="1-3-5-序列化"><a href="#1-3-5-序列化" class="headerlink" title="1.3.5. 序列化"></a>1.3.5. 序列化</h4><p>该模块支持任何 <code>ch.qos.logback.core.encoder.Encoder</code>。这允许您使用能够编码 <code>ILoggingEvent</code>或 <code>IAccessEvent</code> 的任何编码器，<br>如众所周知的<a href="https://logback.qos.ch/manual/encoders.html#PatternLayoutEncoder" target="_blank" rel="noopener">logback PatternLayoutEncoder</a>，<br>或者例如 <a href="https://github.com/logstash/logstash-logback-encoder#usage" target="_blank" rel="noopener">logstash-logback-encoder的LogstashEncoxer</a>。</p>
<h5 id="1-3-5-1-自定义序列化"><a href="#1-3-5-1-自定义序列化" class="headerlink" title="1.3.5.1 自定义序列化"></a>1.3.5.1 自定义序列化</h5><p>如果要在kafka日志记录主题上编写与字符串不同的内容，可以使用编码机制。 用例将是生产或消费方面的较小消息大小和/或更好的序列化/反序列化性能。<br>有用的格式可以是BSON，Avro或其他。</p>
<p>要推出自己的实现，请参阅<a href="https://logback.qos.ch/xref/ch/qos/logback/core/encoder/Encoder.html" target="_blank" rel="noopener">logback文档</a>。<br>请注意，logback-kafka-appender永远不会调用headerBytes（）或footerBytes（）方法。</p>
<p>您的编码器应该针对您要支持的事件类型的任何子类型（通常是 <code>ILoggingEvent</code>）进行类型参数化，例如:</p>
<p><code>public class MyEncoder extends ch.qos.logback.core.encoder.Encoder&lt;ILoggingEvent&gt; {/*..*/}</code></p>
<h3 id="1-4-键控策略-分区-Keying-strategies-Partitioning"><a href="#1-4-键控策略-分区-Keying-strategies-Partitioning" class="headerlink" title="1.4 键控策略/分区:Keying strategies / Partitioning"></a>1.4 键控策略/分区:Keying strategies / Partitioning</h3><p>Kafka的可扩展性和排序保证严重依赖于分区的概念（<a href="https://kafka.apache.org/082/documentation.html#introduction" target="_blank" rel="noopener">这里有更多细节</a>）。<br>对于应用程序日志记录，这意味着我们需要决定如何在多个kafka主题分区上分发日志消息。<br>这个决定的一个含义是消息在从任意多分区消费者消费时如何排序，因为kafka仅在每个单独的分区上提供有保证的读取顺序。<br>另一个含义是我们的日志消息在所有可用分区中的分布均匀，因此在多个代理之间保持平衡。</p>
<p>日志消息的顺序可能重要，也可能不重要，具体取决于预期的消费者 - 受众（例如，logstash索引器无论如何都会按时间戳重新排序所有消息）。</p>
<p>您可以使用partition属性为kafka appender提供固定分区，或让生产者使用消息密钥对消息进行分区。 因此logback-kafka-appender支持以下键控策略策略：</p>
<ul>
<li><p><code>NoKeyKeyingStrategy</code> : </p>
<p>  不生成 message key。如果未提供固定分区，则导致跨分区的循环分布。</p>
</li>
<li><p><code>HostNameKeyingStrategy</code> : </p>
<p>  此策略使用 HOSTNAME 作为 message key。 这很有用，因为它可以确保此主机发出的所有日志消息对于任何使用者都保持正确的顺序。<br>  但是这种策略可能导致少量主机的日志分配不均匀（与分区数量相比）。</p>
</li>
<li><p><code>ContextNameKeyingStrategy</code> : </p>
<p>  此策略使用 logback 的 CONTEXT_NAME 作为 message key。<br>  这可以确保由同一日志记录上下文记录的所有日志消息将保持在任何使用者的正确顺序中。<br>  但是这种策略可能导致少量主机的日志分配不均匀（与分区数量相比）。<br>  此策略仅适用于ILoggingEvents。</p>
</li>
<li><p><code>ThreadNameKeyingStrategy</code> : </p>
<p>  此策略使用调用线程名(thread name)称作为 message key。<br>  这可确保同一线程记录的所有消息将保持正确的顺序，供任何使用者使用。<br>  但是这种策略可能会导致少量线程（-names）的日志分配不均匀（与分区数量相比）。<br>  此策略仅适用于 ILoggingEvents。</p>
</li>
<li><p><code>LoggerNameKeyingStrategy</code> : </p>
<p>  *此策略使用记录器名称(logger name)作为 message key。<br>  这可确保同一记录器记录的所有消息都将保持在任何使用者的正确顺序中。<br>  但是这种策略可能会导致少量不同记录器的日志分配不均匀（与分区数量相比）。<br>  此策略仅适用于 ILoggingEvents。</p>
</li>
</ul>
<h4 id="1-4-1-自定义键控策略-Custom-keying-strategies"><a href="#1-4-1-自定义键控策略-Custom-keying-strategies" class="headerlink" title="1.4.1. 自定义键控策略 Custom keying strategies"></a>1.4.1. 自定义键控策略 Custom keying strategies</h4><p>如果上述键控策略都不满足您的要求，您可以通过实现自定义 KeyingStrategy 轻松实现自己的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> foo;</span><br><span class="line"><span class="keyword">import</span> com.github.danielwegener.logback.kafka.keying.KeyingStrategy;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 这是一个有效的例子，但并没有多大意义 */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LevelKeyingStrategy</span> <span class="keyword">implements</span> <span class="title">KeyingStrategy</span>&lt;<span class="title">ILoggingEvent</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] createKey(ILoggingEvent e) &#123;</span><br><span class="line">        <span class="keyword">return</span> ByteBuffer.allocate(<span class="number">4</span>).putInt(e.getLevel()).array();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>作为大多数自定义 logback 组件，您的自定义分区策略还可以实现 <code>ch.qos.logback.core.spi.ContextAware</code> 和 <code>ch.qos.logback.core.spi.LifeCycle</code> 接口。</p>
<p>当您想要使用kafka的日志压缩工具时，自定义键控策略可能会特别方便。</p>
<h3 id="1-5-logback-spring-xml-示例"><a href="#1-5-logback-spring-xml-示例" class="headerlink" title="1.5. logback-spring.xml 示例"></a>1.5. logback-spring.xml 示例</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">scan</span>=<span class="string">"true"</span> <span class="attr">scanPeriod</span>=<span class="string">"60 seconds"</span> <span class="attr">debug</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">contextName</span>&gt;</span>oauth2-auth-server<span class="tag">&lt;/<span class="name">contextName</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_HOME"</span> <span class="attr">value</span>=<span class="string">"logs"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--输出到控制台--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"console"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-12(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;) %contextName [%thread] %highlight(%-5level) %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--输出到kafka--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"kafka"</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.KafkaAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.encoder.PatternLayoutEncoder"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-12(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;) %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">topic</span>&gt;</span>oauth2-auth-server<span class="tag">&lt;/<span class="name">topic</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 我们不关心如何对日志消息进行分区 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">keyingStrategy</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 使用异步传递。 日志记录不会阻止应用程序线程 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">deliveryStrategy</span> <span class="attr">class</span>=<span class="string">"com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 每个&lt;producerConfig&gt;转换为常规kafka-client配置（格式：key = value） --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 生产者配置记录在这里：https://kafka.apache.org/documentation.html#newproducerconfigs --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- bootstrap.servers是唯一必需的 producerConfig --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>bootstrap.servers=192.168.213.13:9092,192.168.213.14:9092,192.168.213.21:9092<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 不用等待代理对批的接收进行打包。  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>acks=0<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 等待最多1000毫秒并收集日志消息，然后再批量发送 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>linger.ms=1000<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 即使生产者缓冲区运行已满，也不要阻止应用程序而是开始丢弃消息 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>max.block.ms=0<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义用于标识kafka代理的客户端ID --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">producerConfig</span>&gt;</span>client.id=$&#123;HOSTNAME&#125;-$&#123;CONTEXT_NAME&#125;-logback-relaxed<span class="tag">&lt;/<span class="name">producerConfig</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 如果kafka不可用，这是后备appender。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"file"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--输出到文件--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"file"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--日志文件输出的文件名--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">FileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/oauth2-auth-server.log.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">FileNamePattern</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--日志文件保留天数--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">MaxHistory</span>&gt;</span>30<span class="tag">&lt;/<span class="name">MaxHistory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%-12(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;) %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"console"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"kafka"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="2-Kafka-与-Logstash-的集成"><a href="#2-Kafka-与-Logstash-的集成" class="headerlink" title="2. Kafka 与 Logstash 的集成"></a>2. Kafka 与 Logstash 的集成</h2><p>logstash 与 Kafka 的简单配置</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">input</span> <span class="string">&#123;</span></span><br><span class="line">     <span class="string">kafka</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="string">topics</span> <span class="string">=&gt;</span> <span class="string">"applog"</span></span><br><span class="line">        <span class="string">bootstrap_servers</span> <span class="string">=&gt;</span> <span class="string">"Kafka服务器IP:9092,Kafka服务器IP:9092"</span></span><br><span class="line">        <span class="string">codec</span> <span class="string">=&gt;</span> <span class="string">"json"</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">filter</span> <span class="string">&#123;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">output</span> <span class="string">&#123;</span></span><br><span class="line">  <span class="string">//控制台输入</span></span><br><span class="line">  <span class="string">stdout</span> <span class="string">&#123;</span>  <span class="string">codec</span> <span class="string">=&gt;</span> <span class="string">rubydebug</span> <span class="string">&#125;</span></span><br><span class="line">  <span class="string">elasticsearch</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="string">hosts</span> <span class="string">=&gt;</span> <span class="string">[</span> <span class="string">"elasticsearch服务器IP:9200"</span> <span class="string">]</span></span><br><span class="line">    <span class="string">index</span> <span class="string">=&gt;</span> <span class="string">"kafka"</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>启动 logstash：</p>
<p><code>.\bin\logstash -f .\conf\logstash-kaka.conf</code></p>
</section>
    <!-- Tags START -->
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/passages/Spring-Security-Oauth2如何增加自定义授权模式/">
        <span class="nav-arrow">← </span>
        
          Spring-Security-Oauth2如何增加自定义授权模式
        
      </a>
    
    
      <a class="nav-right" href="/passages/spring定时任务详解（-Scheduled注解）/">
        
          spring定时任务详解（@Scheduled注解）
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-logback-与-Kafka-的集成"><span class="toc-nav-text">1. logback 与 Kafka 的集成</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-1-KafkaAppender-配置说明"><span class="toc-nav-text">1.1. KafkaAppender 配置说明</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-2-兼容性-Compatibility"><span class="toc-nav-text">1.2. 兼容性:Compatibility</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-3-分发策略-Delivery-strategies"><span class="toc-nav-text">1.3. 分发策略:Delivery strategies</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-3-1-关于-broker-的中断"><span class="toc-nav-text">1.3.1. 关于 broker 的中断</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-3-2-自定义分发策略-delivery-strategies"><span class="toc-nav-text">1.3.2. 自定义分发策略(delivery strategies)</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-3-3-备用追加程序-fallback-appender"><span class="toc-nav-text">1.3.3. 备用追加程序:fallback appender</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-3-4-生产者调整"><span class="toc-nav-text">1.3.4. 生产者调整</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-3-5-序列化"><span class="toc-nav-text">1.3.5. 序列化</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#1-3-5-1-自定义序列化"><span class="toc-nav-text">1.3.5.1 自定义序列化</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-4-键控策略-分区-Keying-strategies-Partitioning"><span class="toc-nav-text">1.4 键控策略/分区:Keying strategies / Partitioning</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#1-4-1-自定义键控策略-Custom-keying-strategies"><span class="toc-nav-text">1.4.1. 自定义键控策略 Custom keying strategies</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1-5-logback-spring-xml-示例"><span class="toc-nav-text">1.5. logback-spring.xml 示例</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-Kafka-与-Logstash-的集成"><span class="toc-nav-text">2. Kafka 与 Logstash 的集成</span></a></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://yoursite.com/passages/logback-Kafka-logstash集成/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>




  <script>
    var gitmentConfig = "littlefxc";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "logback+Kafka+logstash集成",
        owner: "littlefxc",
        repo: "littlefxc.github.io",
        oauth: {
          client_id: "6bb790335b0d3c3250e1",
          client_secret: "f28da7790bca675951b0b5a339de3845929b9a23"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  </script>




    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2020 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>